
broker.id=1

 #此处的host.name为本机IP(重要),如果不改,则客户端会抛出:Producer connection to localhost:9092 unsuccessful 错误!
#host.name=192.168.0.109

listeners=SASL_PLAINTEXT://0.0.0.0:19093

advertised.listeners=SASL_PLAINTEXT://192.168.0.109:19093

security.inter.broker.protocol=SASL_PLAINTEXT
sasl.enabled.mechanisms=PLAIN
sasl.mechanism.inter.broker.protocol=PLAIN
authorizer.class.name = kafka.security.auth.SimpleAclAuthorizer
allow.everyone.if.no.acl.found=true
super.users=User:root


#处理网络请求的线程数量
num.network.threads=8

#用来处理磁盘IO的线程数量
num.io.threads=8

#发送套接字的缓冲区大小
socket.send.buffer.bytes=102400

#接受套接字的缓冲区大小
socket.receive.buffer.bytes=102400

#请求套接字的缓冲区大小
socket.request.max.bytes=104857600

#kafka运行日志存放的路径
log.dirs=/data/kafka/node1/data

#topic在当前broker上的分片个数
num.partitions=3

#用来恢复和清理data下数据的线程数量
num.recovery.threads.per.data.dir=1

#segment文件保留的最长时间，超时将被删除
log.retention.hours=240

#滚动生成新的segment文件的最大时间
log.roll.hours=240

#日志文件中每个segment的大小，默认为1G
log.segment.bytes=1073741824

#周期性检查文件大小的时间
log.retention.check.interval.ms=300000

#日志清理是否打开
log.cleaner.enable=true

#broker需要使用zookeeper保存meta数据
zookeeper.connect=192.168.0.109:2181,192.168.0.109:2182,192.168.0.109:2183/kafka

#zookeeper链接超时时间
zookeeper.connection.timeout.ms=6000

#partion buffer中，消息的条数达到阈值，将触发flush到磁盘
log.flush.interval.messages=5000

#消息buffer的时间，达到阈值，将触发flush到磁盘
log.flush.interval.ms=1000

#删除topic需要server.properties中设置delete.topic.enable=true否则只是标记删除
delete.topic.enable=false

#当producer设置request.required.acks为-1时，min.insync.replicas指定replicas的最小数目（必须确认每一个repica的写数据都是成功的），如果这个数目没有达到，producer会产生异常。
min.insync.replicas=2
#指明了是否能够使不在ISR中replicas设置用来作为leader
unclean.leader.election.enable=false
#是否自动创建主题
auto.create.topics.enable=false
#默认创建的副本数量
default.replication.factor=3

